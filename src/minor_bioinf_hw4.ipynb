{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка файлов и программ"
      ],
      "metadata": {
        "id": "Q1iydQxRGrI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка HISAT2 (для выравниваия RNA-seq чтений на геном)"
      ],
      "metadata": {
        "id": "CTb3EFUeGtGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwhU-adiGrfR",
        "outputId": "c732dba2-8a0d-4ba6-a535-f090aa873c7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,172 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,512 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,734 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,502 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,618 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,452 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,323 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,223 kB]\n",
            "Fetched 23.9 MB in 9s (2,629 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install hisat2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16NVKYBlG600",
        "outputId": "de7d7040-7e55-4868-f8d8-d06b8f5256fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  bcftools libhts3 libhtscodecs2 python3-hisat2 samtools\n",
            "Suggested packages:\n",
            "  python3-numpy python3-matplotlib texlive-latex-recommended cwltool\n",
            "The following NEW packages will be installed:\n",
            "  bcftools hisat2 libhts3 libhtscodecs2 python3-hisat2 samtools\n",
            "0 upgraded, 6 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 5,505 kB of archives.\n",
            "After this operation, 17.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libhtscodecs2 amd64 1.1.1-3 [53.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libhts3 amd64 1.13+ds-2build1 [390 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 bcftools amd64 1.13-1 [697 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 hisat2 amd64 2.2.1-3 [3,832 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-hisat2 all 2.2.1-3 [12.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 samtools amd64 1.13-4 [520 kB]\n",
            "Fetched 5,505 kB in 0s (15.8 MB/s)\n",
            "Selecting previously unselected package libhtscodecs2:amd64.\n",
            "(Reading database ... 123630 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libhtscodecs2_1.1.1-3_amd64.deb ...\n",
            "Unpacking libhtscodecs2:amd64 (1.1.1-3) ...\n",
            "Selecting previously unselected package libhts3:amd64.\n",
            "Preparing to unpack .../1-libhts3_1.13+ds-2build1_amd64.deb ...\n",
            "Unpacking libhts3:amd64 (1.13+ds-2build1) ...\n",
            "Selecting previously unselected package bcftools.\n",
            "Preparing to unpack .../2-bcftools_1.13-1_amd64.deb ...\n",
            "Unpacking bcftools (1.13-1) ...\n",
            "Selecting previously unselected package hisat2.\n",
            "Preparing to unpack .../3-hisat2_2.2.1-3_amd64.deb ...\n",
            "Unpacking hisat2 (2.2.1-3) ...\n",
            "Selecting previously unselected package python3-hisat2.\n",
            "Preparing to unpack .../4-python3-hisat2_2.2.1-3_all.deb ...\n",
            "Unpacking python3-hisat2 (2.2.1-3) ...\n",
            "Selecting previously unselected package samtools.\n",
            "Preparing to unpack .../5-samtools_1.13-4_amd64.deb ...\n",
            "Unpacking samtools (1.13-4) ...\n",
            "Setting up libhtscodecs2:amd64 (1.1.1-3) ...\n",
            "Setting up libhts3:amd64 (1.13+ds-2build1) ...\n",
            "Setting up bcftools (1.13-1) ...\n",
            "Setting up samtools (1.13-4) ...\n",
            "Setting up hisat2 (2.2.1-3) ...\n",
            "Setting up python3-hisat2 (2.2.1-3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hisat2 --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ65qJKHHAQj",
        "outputId": "8bd68b36-522a-4340-ef7f-86df5573d14b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/hisat2-align-s version 2.2.1\n",
            "64-bit\n",
            "Built on Debian\n",
            "28 September 2021\n",
            "Compiler: gcc version 11.2.0 (Ubuntu 11.2.0-7ubuntu2) \n",
            "Options: -O3   -funroll-loops -g3 -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++11\n",
            "Sizeof {int, long, long long, void*, size_t, off_t}: {4, 8, 8, 8, 8, 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка sra-toolkit (для скачивания .fastq файлов из NCBI)"
      ],
      "metadata": {
        "id": "wG3MF8MwHI0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install sra-toolkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVO9yMc_HJH0",
        "outputId": "74796f08-34fe-4017-8bd7-c692cc6ced82"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  blends-common libkdf5-2 libncbi-vdb2 libncbi-wvdb2 med-config menu\n",
            "Suggested packages:\n",
            "  blends-doc menu-l10n gksu | kde-runtime | ktsuss\n",
            "The following NEW packages will be installed:\n",
            "  blends-common libkdf5-2 libncbi-vdb2 libncbi-wvdb2 med-config menu sra-toolkit\n",
            "0 upgraded, 7 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 8,290 kB of archives.\n",
            "After this operation, 23.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 menu amd64 2.1.47ubuntu4 [354 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 blends-common all 0.7.4ubuntu1 [15.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libkdf5-2 amd64 2.11.2+dfsg-4build2 [14.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libncbi-vdb2 amd64 2.11.2+dfsg-4build2 [1,364 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libncbi-wvdb2 amd64 2.11.2+dfsg-4build2 [1,252 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 sra-toolkit amd64 2.11.3+dfsg-1ubuntu1 [5,277 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 med-config all 3.7.1 [11.6 kB]\n",
            "Fetched 8,290 kB in 0s (22.7 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package menu.\n",
            "(Reading database ... 123830 files and directories currently installed.)\n",
            "Preparing to unpack .../0-menu_2.1.47ubuntu4_amd64.deb ...\n",
            "Unpacking menu (2.1.47ubuntu4) ...\n",
            "Selecting previously unselected package blends-common.\n",
            "Preparing to unpack .../1-blends-common_0.7.4ubuntu1_all.deb ...\n",
            "Unpacking blends-common (0.7.4ubuntu1) ...\n",
            "Selecting previously unselected package libkdf5-2.\n",
            "Preparing to unpack .../2-libkdf5-2_2.11.2+dfsg-4build2_amd64.deb ...\n",
            "Unpacking libkdf5-2 (2.11.2+dfsg-4build2) ...\n",
            "Selecting previously unselected package libncbi-vdb2.\n",
            "Preparing to unpack .../3-libncbi-vdb2_2.11.2+dfsg-4build2_amd64.deb ...\n",
            "Unpacking libncbi-vdb2 (2.11.2+dfsg-4build2) ...\n",
            "Selecting previously unselected package libncbi-wvdb2.\n",
            "Preparing to unpack .../4-libncbi-wvdb2_2.11.2+dfsg-4build2_amd64.deb ...\n",
            "Unpacking libncbi-wvdb2 (2.11.2+dfsg-4build2) ...\n",
            "Selecting previously unselected package sra-toolkit.\n",
            "Preparing to unpack .../5-sra-toolkit_2.11.3+dfsg-1ubuntu1_amd64.deb ...\n",
            "Unpacking sra-toolkit (2.11.3+dfsg-1ubuntu1) ...\n",
            "Selecting previously unselected package med-config.\n",
            "Preparing to unpack .../6-med-config_3.7.1_all.deb ...\n",
            "Unpacking med-config (3.7.1) ...\n",
            "Setting up libncbi-vdb2 (2.11.2+dfsg-4build2) ...\n",
            "Setting up libkdf5-2 (2.11.2+dfsg-4build2) ...\n",
            "Setting up libncbi-wvdb2 (2.11.2+dfsg-4build2) ...\n",
            "Setting up menu (2.1.47ubuntu4) ...\n",
            "Setting up blends-common (0.7.4ubuntu1) ...\n",
            "Setting up sra-toolkit (2.11.3+dfsg-1ubuntu1) ...\n",
            "Setting up med-config (3.7.1) ...\n",
            "Adding group `med' (GID 107) ...\n",
            "Done.\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for menu (2.1.47ubuntu4) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка FastQC"
      ],
      "metadata": {
        "id": "gEmx751SHqZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6dqPr_bHq90",
        "outputId": "9547881d-abb5-413a-cb3d-57d322965973"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.25\" 2024-10-15\n",
            "OpenJDK Runtime Environment (build 11.0.25+9-post-Ubuntu-1ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.25+9-post-Ubuntu-1ubuntu122.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.9.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV8mHRz8Hwe9",
        "outputId": "5cf93267-9042-481e-c1ca-6bebf35a6142"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-23 10:44:42--  https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.9.zip\n",
            "Resolving www.bioinformatics.babraham.ac.uk (www.bioinformatics.babraham.ac.uk)... 149.155.133.4\n",
            "Connecting to www.bioinformatics.babraham.ac.uk (www.bioinformatics.babraham.ac.uk)|149.155.133.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10249221 (9.8M) [application/zip]\n",
            "Saving to: ‘fastqc_v0.11.9.zip’\n",
            "\n",
            "fastqc_v0.11.9.zip  100%[===================>]   9.77M  10.3MB/s    in 0.9s    \n",
            "\n",
            "2024-11-23 10:44:43 (10.3 MB/s) - ‘fastqc_v0.11.9.zip’ saved [10249221/10249221]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip fastqc_v0.11.9.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZBQhmFKHyiz",
        "outputId": "b55514c8-22e3-407e-a73b-6f2d927936b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  fastqc_v0.11.9.zip\n",
            "  inflating: FastQC/cisd-jhdf5.jar   \n",
            "   creating: FastQC/Configuration/\n",
            "  inflating: FastQC/Configuration/adapter_list.txt  \n",
            "  inflating: FastQC/Configuration/contaminant_list.txt  \n",
            "  inflating: FastQC/Configuration/limits.txt  \n",
            "  inflating: FastQC/fastqc           \n",
            "  inflating: FastQC/fastqc_icon.ico  \n",
            "   creating: FastQC/Help/\n",
            "   creating: FastQC/Help/1 Introduction/\n",
            "   creating: FastQC/Help/1 Introduction/.svn/\n",
            "  inflating: FastQC/Help/1 Introduction/.svn/entries  \n",
            "   creating: FastQC/Help/1 Introduction/.svn/props/\n",
            "   creating: FastQC/Help/1 Introduction/.svn/text-base/\n",
            "  inflating: FastQC/Help/1 Introduction/.svn/text-base/1.1 What is FastQC.html.svn-base  \n",
            "   creating: FastQC/Help/1 Introduction/.svn/tmp/\n",
            "   creating: FastQC/Help/1 Introduction/.svn/tmp/props/\n",
            "  inflating: FastQC/Help/1 Introduction/1.1 What is FastQC.html  \n",
            "   creating: FastQC/Help/2 Basic Operations/\n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/\n",
            "  inflating: FastQC/Help/2 Basic Operations/.svn/entries  \n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/props/\n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/text-base/\n",
            "  inflating: FastQC/Help/2 Basic Operations/.svn/text-base/2.1 Opening a sequence file.html.svn-base  \n",
            "  inflating: FastQC/Help/2 Basic Operations/.svn/text-base/2.2 Evaluating Results.html.svn-base  \n",
            "  inflating: FastQC/Help/2 Basic Operations/.svn/text-base/2.3 Saving a Report.html.svn-base  \n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/tmp/\n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/tmp/props/\n",
            "  inflating: FastQC/Help/2 Basic Operations/2.1 Opening a sequence file.html  \n",
            "  inflating: FastQC/Help/2 Basic Operations/2.2 Evaluating Results.html  \n",
            "  inflating: FastQC/Help/2 Basic Operations/2.3 Saving a Report.html  \n",
            "   creating: FastQC/Help/3 Analysis Modules/\n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/\n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/entries  \n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/prop-base/\n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/duplication_levels.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/prop-base/kmer_profiles.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_gc_content.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_n_content.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_quality.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_sequence_content.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_sequence_gc_content.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_sequence_quality.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_tile_quality.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/sequence_length_distribution.png.svn-base  \n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/props/\n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/text-base/\n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/1 Basic Statistics.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/10 Adapter Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/11 Kmer Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/12 Per Tile Sequence Quality.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/2 Per Base Sequence Quality.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/3 Per Sequence Quality Scores.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/4 Per Base Sequence Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/5 Per Sequence GC Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/6 Per Base N Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/7 Sequence Length Distribution.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/8 Duplicate Sequences.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/9 Overrepresented Sequences.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/duplication_levels.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/kmer_profiles.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_gc_content.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_n_content.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_quality.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_sequence_content.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_sequence_gc_content.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_sequence_quality.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_tile_quality.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/sequence_length_distribution.png.svn-base  \n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/tmp/\n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/tmp/props/\n",
            "  inflating: FastQC/Help/3 Analysis Modules/1 Basic Statistics.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/10 Adapter Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/11 Kmer Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/12 Per Tile Sequence Quality.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/2 Per Base Sequence Quality.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/3 Per Sequence Quality Scores.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/4 Per Base Sequence Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/5 Per Sequence GC Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/6 Per Base N Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/7 Sequence Length Distribution.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/8 Duplicate Sequences.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/9 Overrepresented Sequences.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/duplication_levels.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/kmer_profiles.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_base_gc_content.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_base_n_content.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_base_quality.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_base_sequence_content.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_sequence_gc_content.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_sequence_quality.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_tile_quality.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/sequence_length_distribution.png  \n",
            "  inflating: FastQC/INSTALL.txt      \n",
            "  inflating: FastQC/jbzip2-0.9.jar   \n",
            "  inflating: FastQC/LICENSE          \n",
            "  inflating: FastQC/LICENSE.txt      \n",
            "  inflating: FastQC/LICENSE_JHDF5.txt  \n",
            "   creating: FastQC/net/\n",
            "   creating: FastQC/net/sourceforge/\n",
            "   creating: FastQC/net/sourceforge/iharder/\n",
            "   creating: FastQC/net/sourceforge/iharder/base64/\n",
            "  inflating: FastQC/net/sourceforge/iharder/base64/Base64$1.class  \n",
            "  inflating: FastQC/net/sourceforge/iharder/base64/Base64$InputStream.class  \n",
            "  inflating: FastQC/net/sourceforge/iharder/base64/Base64$OutputStream.class  \n",
            "  inflating: FastQC/net/sourceforge/iharder/base64/Base64.class  \n",
            "   creating: FastQC/org/\n",
            "   creating: FastQC/org/apache/\n",
            "   creating: FastQC/org/apache/commons/\n",
            "   creating: FastQC/org/apache/commons/math3/\n",
            "   creating: FastQC/org/apache/commons/math3/analysis/\n",
            "   creating: FastQC/org/apache/commons/math3/analysis/solvers/\n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/AbstractUnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/AllowedSolution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BaseAbstractUnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BaseUnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BracketedUnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BrentSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/UnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/UnivariateSolverUtils.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/UnivariateFunction.class  \n",
            "   creating: FastQC/org/apache/commons/math3/distribution/\n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/AbstractIntegerDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/AbstractRealDistribution$1.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/AbstractRealDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/BetaDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/BinomialDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/CauchyDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/ChiSquaredDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/FDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/GammaDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/HypergeometricDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/IntegerDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/NormalDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/PascalDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/PoissonDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/RealDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/SaddlePointExpansion.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/TDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/WeibullDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/ZipfDistribution.class  \n",
            "   creating: FastQC/org/apache/commons/math3/exception/\n",
            "  inflating: FastQC/org/apache/commons/math3/exception/ConvergenceException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/DimensionMismatchException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathArithmeticException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathIllegalArgumentException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathIllegalNumberException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathIllegalStateException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathInternalError.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MaxCountExceededException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NoBracketingException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NotFiniteNumberException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NotPositiveException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NotStrictlyPositiveException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NullArgumentException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NumberIsTooLargeException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NumberIsTooSmallException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/OutOfRangeException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/TooManyEvaluationsException.class  \n",
            "   creating: FastQC/org/apache/commons/math3/exception/util/\n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/ArgUtils.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/ExceptionContext.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/ExceptionContextProvider.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/Localizable.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/LocalizedFormats.class  \n",
            "   creating: FastQC/org/apache/commons/math3/random/\n",
            "  inflating: FastQC/org/apache/commons/math3/random/AbstractWell.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/BitsStreamGenerator.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/RandomData.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/RandomDataImpl.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/RandomGenerator.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/Well19937c.class  \n",
            "   creating: FastQC/org/apache/commons/math3/special/\n",
            "  inflating: FastQC/org/apache/commons/math3/special/Beta$1.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/special/Beta.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/special/Erf.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/special/Gamma$1.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/special/Gamma.class  \n",
            "   creating: FastQC/org/apache/commons/math3/util/\n",
            "  inflating: FastQC/org/apache/commons/math3/util/ArithmeticUtils.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/ContinuedFraction.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/DoubleArray.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMath$ExpFracTable.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMath$ExpIntTable.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMath$lnMant.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMath.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMathCalc.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMathLiteralArrays.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/Incrementor$1.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/Incrementor$MaxCountExceededCallback.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/Incrementor.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/MathUtils.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/Precision.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/ResizableDoubleArray.class  \n",
            "  inflating: FastQC/README.md        \n",
            "  inflating: FastQC/README.txt       \n",
            "  inflating: FastQC/RELEASE_NOTES.txt  \n",
            "  inflating: FastQC/run_fastqc.bat   \n",
            "  inflating: FastQC/sam-1.103.jar    \n",
            "   creating: FastQC/Templates/\n",
            "  inflating: FastQC/Templates/fastqc2fo.xsl  \n",
            "  inflating: FastQC/Templates/header_template.html  \n",
            "   creating: FastQC/Templates/Icons/\n",
            " extracting: FastQC/Templates/Icons/error.png  \n",
            " extracting: FastQC/Templates/Icons/fastqc_icon.png  \n",
            " extracting: FastQC/Templates/Icons/tick.png  \n",
            " extracting: FastQC/Templates/Icons/warning.png  \n",
            "   creating: FastQC/uk/\n",
            "   creating: FastQC/uk/ac/\n",
            "   creating: FastQC/uk/ac/babraham/\n",
            "   creating: FastQC/uk/ac/babraham/FastQC/\n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Analysis/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/AnalysisListener.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/AnalysisQueue.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/AnalysisRunner.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/OfflineRunner.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Dialogs/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/AboutDialog$1.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/AboutDialog.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/FastQCTitlePanel$SmoothJLabel.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/FastQCTitlePanel.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/WelcomePanel.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCApplication$1.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCApplication.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCConfig.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCMenuBar.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/FileFilters/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/BAMFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/CasavaFastQFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/FastQFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/GobyFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/MappedBAMFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/SequenceFileFilter.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Graphs/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/BaseGroup.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/LineGraph.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/QualityBoxPlot.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/TileGraph.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Help/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpDialog.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpIndexRoot$FileSorter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpIndexRoot.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpPage.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpPageDisplay$HelpEditor.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpPageDisplay.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpSearchPanel.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Modules/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AbstractQCModule.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AdapterContent$Adapter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AdapterContent$ResultsTable.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AdapterContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/BasicStats$ResultsTable.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/BasicStats.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/DuplicationLevel.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Modules/GCModel/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/GCModel/GCModel.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/GCModel/GCModelValue.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/KmerContent$Kmer.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/KmerContent$ResultsTable.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/KmerContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/ModuleConfig.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/ModuleFactory.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/NContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/OverRepresentedSeqs$OverrepresentedSeq.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/OverRepresentedSeqs$ResultsTable.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/OverRepresentedSeqs.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerBaseQualityScores.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerBaseSequenceContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerSequenceGCContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerSequenceQualityScores.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerTileQualityScores.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/QCModule.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/SequenceLengthDistribution.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Report/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Report/HTMLReportArchive.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Report/stylesheet.txt  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Resources/\n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/error.png  \n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/fastqc_icon.png  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Resources/fastqc_icon.svg  \n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/fastqc_icon_100.png  \n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/tick.png  \n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/warning.png  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Results/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Results/ResultsPanel$ModuleRenderer.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Results/ResultsPanel.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Sequence/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/BAMFile.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/Contaminant.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/ContaminantHit.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/ContaminentFinder.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Fast5File.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/FastQFile.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Sequence/QualityEncoding/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/QualityEncoding/PhredEncoding.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Sequence.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFactory.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFile.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFileGroup.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFormatException.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Statistics/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Statistics/NormalDistribution.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Statistics/PearsonCorrelation.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Utilities/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/CasavaBasename.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/HotColdColourGradient.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/ImageToBase64.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/MultiMemberGZIPInputStream.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/NameFormatException.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/NanoporeBasename.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/QualityCount.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/RGB.class  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod a+x FastQC/fastqc"
      ],
      "metadata": {
        "id": "AoM0GCf3H1Ue"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./FastQC/fastqc --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB78hYG8H7t4",
        "outputId": "ad7a0213-e513-4aaf-e07d-be545f9392d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            FastQC - A high throughput sequence QC analysis tool\n",
            "\n",
            "SYNOPSIS\n",
            "\n",
            "\tfastqc seqfile1 seqfile2 .. seqfileN\n",
            "\n",
            "    fastqc [-o output dir] [--(no)extract] [-f fastq|bam|sam] \n",
            "           [-c contaminant file] seqfile1 .. seqfileN\n",
            "\n",
            "DESCRIPTION\n",
            "\n",
            "    FastQC reads a set of sequence files and produces from each one a quality\n",
            "    control report consisting of a number of different modules, each one of \n",
            "    which will help to identify a different potential type of problem in your\n",
            "    data.\n",
            "    \n",
            "    If no files to process are specified on the command line then the program\n",
            "    will start as an interactive graphical application.  If files are provided\n",
            "    on the command line then the program will run with no user interaction\n",
            "    required.  In this mode it is suitable for inclusion into a standardised\n",
            "    analysis pipeline.\n",
            "    \n",
            "    The options for the program as as follows:\n",
            "    \n",
            "    -h --help       Print this help file and exit\n",
            "    \n",
            "    -v --version    Print the version of the program and exit\n",
            "    \n",
            "    -o --outdir     Create all output files in the specified output directory.\n",
            "                    Please note that this directory must exist as the program\n",
            "                    will not create it.  If this option is not set then the \n",
            "                    output file for each sequence file is created in the same\n",
            "                    directory as the sequence file which was processed.\n",
            "                    \n",
            "    --casava        Files come from raw casava output. Files in the same sample\n",
            "                    group (differing only by the group number) will be analysed\n",
            "                    as a set rather than individually. Sequences with the filter\n",
            "                    flag set in the header will be excluded from the analysis.\n",
            "                    Files must have the same names given to them by casava\n",
            "                    (including being gzipped and ending with .gz) otherwise they\n",
            "                    won't be grouped together correctly.\n",
            "                    \n",
            "    --nano          Files come from nanopore sequences and are in fast5 format. In\n",
            "                    this mode you can pass in directories to process and the program\n",
            "                    will take in all fast5 files within those directories and produce\n",
            "                    a single output file from the sequences found in all files.                    \n",
            "                    \n",
            "    --nofilter      If running with --casava then don't remove read flagged by\n",
            "                    casava as poor quality when performing the QC analysis.\n",
            "                   \n",
            "    --extract       If set then the zipped output file will be uncompressed in\n",
            "                    the same directory after it has been created.  By default\n",
            "                    this option will be set if fastqc is run in non-interactive\n",
            "                    mode.\n",
            "                    \n",
            "    -j --java       Provides the full path to the java binary you want to use to\n",
            "                    launch fastqc. If not supplied then java is assumed to be in\n",
            "                    your path.\n",
            "                   \n",
            "    --noextract     Do not uncompress the output file after creating it.  You\n",
            "                    should set this option if you do not wish to uncompress\n",
            "                    the output when running in non-interactive mode.\n",
            "                    \n",
            "    --nogroup       Disable grouping of bases for reads >50bp. All reports will\n",
            "                    show data for every base in the read.  WARNING: Using this\n",
            "                    option will cause fastqc to crash and burn if you use it on\n",
            "                    really long reads, and your plots may end up a ridiculous size.\n",
            "                    You have been warned!\n",
            "                    \n",
            "    --min_length    Sets an artificial lower limit on the length of the sequence\n",
            "                    to be shown in the report.  As long as you set this to a value\n",
            "                    greater or equal to your longest read length then this will be\n",
            "                    the sequence length used to create your read groups.  This can\n",
            "                    be useful for making directly comaparable statistics from \n",
            "                    datasets with somewhat variable read lengths.\n",
            "                    \n",
            "    -f --format     Bypasses the normal sequence file format detection and\n",
            "                    forces the program to use the specified format.  Valid\n",
            "                    formats are bam,sam,bam_mapped,sam_mapped and fastq\n",
            "                    \n",
            "    -t --threads    Specifies the number of files which can be processed\n",
            "                    simultaneously.  Each thread will be allocated 250MB of\n",
            "                    memory so you shouldn't run more threads than your\n",
            "                    available memory will cope with, and not more than\n",
            "                    6 threads on a 32 bit machine\n",
            "                  \n",
            "    -c              Specifies a non-default file which contains the list of\n",
            "    --contaminants  contaminants to screen overrepresented sequences against.\n",
            "                    The file must contain sets of named contaminants in the\n",
            "                    form name[tab]sequence.  Lines prefixed with a hash will\n",
            "                    be ignored.\n",
            "\n",
            "    -a              Specifies a non-default file which contains the list of\n",
            "    --adapters      adapter sequences which will be explicity searched against\n",
            "                    the library. The file must contain sets of named adapters\n",
            "                    in the form name[tab]sequence.  Lines prefixed with a hash\n",
            "                    will be ignored.\n",
            "                    \n",
            "    -l              Specifies a non-default file which contains a set of criteria\n",
            "    --limits        which will be used to determine the warn/error limits for the\n",
            "                    various modules.  This file can also be used to selectively \n",
            "                    remove some modules from the output all together.  The format\n",
            "                    needs to mirror the default limits.txt file found in the\n",
            "                    Configuration folder.\n",
            "                    \n",
            "   -k --kmers       Specifies the length of Kmer to look for in the Kmer content\n",
            "                    module. Specified Kmer length must be between 2 and 10. Default\n",
            "                    length is 7 if not specified.\n",
            "                    \n",
            "   -q --quiet       Supress all progress messages on stdout and only report errors.\n",
            "   \n",
            "   -d --dir         Selects a directory to be used for temporary files written when\n",
            "                    generating report images. Defaults to system temp directory if\n",
            "                    not specified.\n",
            "                    \n",
            "BUGS\n",
            "\n",
            "    Any bugs in fastqc should be reported either to simon.andrews@babraham.ac.uk\n",
            "    or in www.bioinformatics.babraham.ac.uk/bugzilla/\n",
            "                   \n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка HTSeq-count"
      ],
      "metadata": {
        "id": "ynn5z901H-MU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install HTSeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG5knMlJH-iw",
        "outputId": "8ada5ff8-870d-4472-cf9e-2b99efeb2253"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting HTSeq\n",
            "  Downloading HTSeq-2.0.9-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from HTSeq) (1.26.4)\n",
            "Collecting pysam (from HTSeq)\n",
            "  Downloading pysam-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Downloading HTSeq-2.0.9-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysam-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl (22.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pysam, HTSeq\n",
            "Successfully installed HTSeq-2.0.9 pysam-0.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!htseq-count --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR-82IL_IDyV",
        "outputId": "af52ead3-ba5c-4f49-c5d2-582532fe3212"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Скачиваем RNA-seq данные"
      ],
      "metadata": {
        "id": "nb5w-9INIKV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Перепрограммированные образцы: \tSRR3414629, SRR3414630, SRR3414631\n",
        "* Контрольные образцы:\t\tSRR3414635, SRR3414636, SRR3414637"
      ],
      "metadata": {
        "id": "WVEYKbgAIMQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!time  fastq-dump  --split-files  SRR3414636"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yECVKZfjIOWy",
        "outputId": "8ea0f357-9825-437b-adee-aa61b9f0041d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 20307147 spots for SRR3414636\n",
            "Written 20307147 spots for SRR3414636\n",
            "\n",
            "real\t5m43.871s\n",
            "user\t4m6.544s\n",
            "sys\t0m14.639s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time  fastq-dump  --split-files  SRR3414629"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnPAC9l2Kba2",
        "outputId": "226da6ec-018b-49f9-e4df-bf46973bf683"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 21106089 spots for SRR3414629\n",
            "Written 21106089 spots for SRR3414629\n",
            "\n",
            "real\t6m54.984s\n",
            "user\t4m55.408s\n",
            "sys\t0m18.891s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time  fastq-dump  --split-files  SRR3414630"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7IYDaauNOIx",
        "outputId": "049a25b4-dcc2-4d5a-b85b-fcc1e14e5df6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 15244711 spots for SRR3414630\n",
            "Written 15244711 spots for SRR3414630\n",
            "\n",
            "real\t4m31.875s\n",
            "user\t3m7.160s\n",
            "sys\t0m13.108s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time  fastq-dump  --split-files  SRR3414631"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3TH9AmcOckF",
        "outputId": "1751839d-aef8-4c0e-f80c-9f13d47e695a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 24244069 spots for SRR3414631\n",
            "Written 24244069 spots for SRR3414631\n",
            "\n",
            "real\t7m52.255s\n",
            "user\t5m19.828s\n",
            "sys\t0m24.212s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time  fastq-dump  --split-files  SRR3414635"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPcW9tAQQVhv",
        "outputId": "64cb6942-7740-4a87-b2aa-d167dbffdd32"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 20956475 spots for SRR3414635\n",
            "Written 20956475 spots for SRR3414635\n",
            "\n",
            "real\t6m43.965s\n",
            "user\t4m36.552s\n",
            "sys\t0m20.893s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time  fastq-dump  --split-files  SRR3414637"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NatS5sv4SHjU",
        "outputId": "f0cf7938-5e5a-4af4-c4c9-280f63a27534"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 20385570 spots for SRR3414637\n",
            "Written 20385570 spots for SRR3414637\n",
            "\n",
            "real\t6m39.120s\n",
            "user\t4m30.475s\n",
            "sys\t0m20.095s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Скачивание генома мыши mm10 (проиндексированный для HISAT2) и аннотацию генов GENCODE"
      ],
      "metadata": {
        "id": "Fn1Ua1sLo50z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://genome-idx.s3.amazonaws.com/hisat/mm10_genome.tar.gz\n",
        "\n",
        "!tar -xzvf mm10_genome.tar.gz\n",
        "\n",
        "!wget http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz\n",
        "\n",
        "!gzip -d gencode.vM25.annotation.gtf.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGlXKlaRo_nt",
        "outputId": "eadc6f62-c90c-47b4-f71a-16a3c02c293b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-22 17:34:02--  https://genome-idx.s3.amazonaws.com/hisat/mm10_genome.tar.gz\n",
            "Resolving genome-idx.s3.amazonaws.com (genome-idx.s3.amazonaws.com)... 54.231.230.49, 16.15.194.140, 54.231.195.161, ...\n",
            "Connecting to genome-idx.s3.amazonaws.com (genome-idx.s3.amazonaws.com)|54.231.230.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3804366597 (3.5G) [binary/octet-stream]\n",
            "Saving to: ‘mm10_genome.tar.gz’\n",
            "\n",
            "mm10_genome.tar.gz  100%[===================>]   3.54G  26.5MB/s    in 93s     \n",
            "\n",
            "2024-11-22 17:35:35 (39.0 MB/s) - ‘mm10_genome.tar.gz’ saved [3804366597/3804366597]\n",
            "\n",
            "mm10/\n",
            "mm10/genome.8.ht2\n",
            "mm10/genome.5.ht2\n",
            "mm10/make_mm10.sh\n",
            "mm10/genome.7.ht2\n",
            "mm10/genome.6.ht2\n",
            "mm10/genome.4.ht2\n",
            "mm10/genome.3.ht2\n",
            "mm10/genome.1.ht2\n",
            "mm10/genome.2.ht2\n",
            "--2024-11-22 17:37:06--  http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz\n",
            "Resolving ftp.ebi.ac.uk (ftp.ebi.ac.uk)... 193.62.193.165\n",
            "Connecting to ftp.ebi.ac.uk (ftp.ebi.ac.uk)|193.62.193.165|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28542432 (27M) [application/x-gzip]\n",
            "Saving to: ‘gencode.vM25.annotation.gtf.gz’\n",
            "\n",
            "gencode.vM25.annota 100%[===================>]  27.22M   888KB/s    in 31s     \n",
            "\n",
            "2024-11-22 17:37:39 (888 KB/s) - ‘gencode.vM25.annotation.gtf.gz’ saved [28542432/28542432]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выравнивание чтений"
      ],
      "metadata": {
        "id": "pDgcdKtiUET4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для каждого образца запускаю FastQC. Скачиваю полученные html файлы и проверяю есть ли проблемы с файлами. Можно также установить multiqc и получить объединенный .html файл. Полученные результаты приводим в отчете на Github-е."
      ],
      "metadata": {
        "id": "szqgSgfDUIXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./FastQC/fastqc  /content/SRR3414629_1.fastq\n",
        "\n",
        "!./FastQC/fastqc  /content/SRR3414630_1.fastq\n",
        "\n",
        "!./FastQC/fastqc  /content/SRR3414631_1.fastq\n",
        "\n",
        "!./FastQC/fastqc  /content/SRR3414635_1.fastq\n",
        "\n",
        "!./FastQC/fastqc  /content/SRR3414636_1.fastq\n",
        "\n",
        "!./FastQC/fastqc  /content/SRR3414637_1.fastq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hECODRNGUE5x",
        "outputId": "fe046d8f-7e56-4a3f-d7bc-f3f0cdcd3726"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started analysis of SRR3414629_1.fastq\n",
            "Approx 5% complete for SRR3414629_1.fastq\n",
            "Approx 10% complete for SRR3414629_1.fastq\n",
            "Approx 15% complete for SRR3414629_1.fastq\n",
            "Approx 20% complete for SRR3414629_1.fastq\n",
            "Approx 25% complete for SRR3414629_1.fastq\n",
            "Approx 30% complete for SRR3414629_1.fastq\n",
            "Approx 35% complete for SRR3414629_1.fastq\n",
            "Approx 40% complete for SRR3414629_1.fastq\n",
            "Approx 45% complete for SRR3414629_1.fastq\n",
            "Approx 50% complete for SRR3414629_1.fastq\n",
            "Approx 55% complete for SRR3414629_1.fastq\n",
            "Approx 60% complete for SRR3414629_1.fastq\n",
            "Approx 65% complete for SRR3414629_1.fastq\n",
            "Approx 70% complete for SRR3414629_1.fastq\n",
            "Approx 75% complete for SRR3414629_1.fastq\n",
            "Approx 80% complete for SRR3414629_1.fastq\n",
            "Approx 85% complete for SRR3414629_1.fastq\n",
            "Approx 90% complete for SRR3414629_1.fastq\n",
            "Approx 95% complete for SRR3414629_1.fastq\n",
            "Analysis complete for SRR3414629_1.fastq\n",
            "Started analysis of SRR3414630_1.fastq\n",
            "Approx 5% complete for SRR3414630_1.fastq\n",
            "Approx 10% complete for SRR3414630_1.fastq\n",
            "Approx 15% complete for SRR3414630_1.fastq\n",
            "Approx 20% complete for SRR3414630_1.fastq\n",
            "Approx 25% complete for SRR3414630_1.fastq\n",
            "Approx 30% complete for SRR3414630_1.fastq\n",
            "Approx 35% complete for SRR3414630_1.fastq\n",
            "Approx 40% complete for SRR3414630_1.fastq\n",
            "Approx 45% complete for SRR3414630_1.fastq\n",
            "Approx 50% complete for SRR3414630_1.fastq\n",
            "Approx 55% complete for SRR3414630_1.fastq\n",
            "Approx 60% complete for SRR3414630_1.fastq\n",
            "Approx 65% complete for SRR3414630_1.fastq\n",
            "Approx 70% complete for SRR3414630_1.fastq\n",
            "Approx 75% complete for SRR3414630_1.fastq\n",
            "Approx 80% complete for SRR3414630_1.fastq\n",
            "Approx 85% complete for SRR3414630_1.fastq\n",
            "Approx 90% complete for SRR3414630_1.fastq\n",
            "Approx 95% complete for SRR3414630_1.fastq\n",
            "Analysis complete for SRR3414630_1.fastq\n",
            "Started analysis of SRR3414631_1.fastq\n",
            "Approx 5% complete for SRR3414631_1.fastq\n",
            "Approx 10% complete for SRR3414631_1.fastq\n",
            "Approx 15% complete for SRR3414631_1.fastq\n",
            "Approx 20% complete for SRR3414631_1.fastq\n",
            "Approx 25% complete for SRR3414631_1.fastq\n",
            "Approx 30% complete for SRR3414631_1.fastq\n",
            "Approx 35% complete for SRR3414631_1.fastq\n",
            "Approx 40% complete for SRR3414631_1.fastq\n",
            "Approx 45% complete for SRR3414631_1.fastq\n",
            "Approx 50% complete for SRR3414631_1.fastq\n",
            "Approx 55% complete for SRR3414631_1.fastq\n",
            "Approx 60% complete for SRR3414631_1.fastq\n",
            "Approx 65% complete for SRR3414631_1.fastq\n",
            "Approx 70% complete for SRR3414631_1.fastq\n",
            "Approx 75% complete for SRR3414631_1.fastq\n",
            "Approx 80% complete for SRR3414631_1.fastq\n",
            "Approx 85% complete for SRR3414631_1.fastq\n",
            "Approx 90% complete for SRR3414631_1.fastq\n",
            "Approx 95% complete for SRR3414631_1.fastq\n",
            "Analysis complete for SRR3414631_1.fastq\n",
            "Started analysis of SRR3414635_1.fastq\n",
            "Approx 5% complete for SRR3414635_1.fastq\n",
            "Approx 10% complete for SRR3414635_1.fastq\n",
            "Approx 15% complete for SRR3414635_1.fastq\n",
            "Approx 20% complete for SRR3414635_1.fastq\n",
            "Approx 25% complete for SRR3414635_1.fastq\n",
            "Approx 30% complete for SRR3414635_1.fastq\n",
            "Approx 35% complete for SRR3414635_1.fastq\n",
            "Approx 40% complete for SRR3414635_1.fastq\n",
            "Approx 45% complete for SRR3414635_1.fastq\n",
            "Approx 50% complete for SRR3414635_1.fastq\n",
            "Approx 55% complete for SRR3414635_1.fastq\n",
            "Approx 60% complete for SRR3414635_1.fastq\n",
            "Approx 65% complete for SRR3414635_1.fastq\n",
            "Approx 70% complete for SRR3414635_1.fastq\n",
            "Approx 75% complete for SRR3414635_1.fastq\n",
            "Approx 80% complete for SRR3414635_1.fastq\n",
            "Approx 85% complete for SRR3414635_1.fastq\n",
            "Approx 90% complete for SRR3414635_1.fastq\n",
            "Approx 95% complete for SRR3414635_1.fastq\n",
            "Analysis complete for SRR3414635_1.fastq\n",
            "Started analysis of SRR3414636_1.fastq\n",
            "Approx 5% complete for SRR3414636_1.fastq\n",
            "Approx 10% complete for SRR3414636_1.fastq\n",
            "Approx 15% complete for SRR3414636_1.fastq\n",
            "Approx 20% complete for SRR3414636_1.fastq\n",
            "Approx 25% complete for SRR3414636_1.fastq\n",
            "Approx 30% complete for SRR3414636_1.fastq\n",
            "Approx 35% complete for SRR3414636_1.fastq\n",
            "Approx 40% complete for SRR3414636_1.fastq\n",
            "Approx 45% complete for SRR3414636_1.fastq\n",
            "Approx 50% complete for SRR3414636_1.fastq\n",
            "Approx 55% complete for SRR3414636_1.fastq\n",
            "Approx 60% complete for SRR3414636_1.fastq\n",
            "Approx 65% complete for SRR3414636_1.fastq\n",
            "Approx 70% complete for SRR3414636_1.fastq\n",
            "Approx 75% complete for SRR3414636_1.fastq\n",
            "Approx 80% complete for SRR3414636_1.fastq\n",
            "Approx 85% complete for SRR3414636_1.fastq\n",
            "Approx 90% complete for SRR3414636_1.fastq\n",
            "Approx 95% complete for SRR3414636_1.fastq\n",
            "Analysis complete for SRR3414636_1.fastq\n",
            "Started analysis of SRR3414637_1.fastq\n",
            "Approx 5% complete for SRR3414637_1.fastq\n",
            "Approx 10% complete for SRR3414637_1.fastq\n",
            "Approx 15% complete for SRR3414637_1.fastq\n",
            "Approx 20% complete for SRR3414637_1.fastq\n",
            "Approx 25% complete for SRR3414637_1.fastq\n",
            "Approx 30% complete for SRR3414637_1.fastq\n",
            "Approx 35% complete for SRR3414637_1.fastq\n",
            "Approx 40% complete for SRR3414637_1.fastq\n",
            "Approx 45% complete for SRR3414637_1.fastq\n",
            "Approx 50% complete for SRR3414637_1.fastq\n",
            "Approx 55% complete for SRR3414637_1.fastq\n",
            "Approx 60% complete for SRR3414637_1.fastq\n",
            "Approx 65% complete for SRR3414637_1.fastq\n",
            "Approx 70% complete for SRR3414637_1.fastq\n",
            "Approx 75% complete for SRR3414637_1.fastq\n",
            "Approx 80% complete for SRR3414637_1.fastq\n",
            "Approx 85% complete for SRR3414637_1.fastq\n",
            "Approx 90% complete for SRR3414637_1.fastq\n",
            "Approx 95% complete for SRR3414637_1.fastq\n",
            "Analysis complete for SRR3414637_1.fastq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install multiqc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_sR1SAZc1XA",
        "outputId": "2269d0bb-9317-4c17-93ac-518c2e9287f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting multiqc\n",
            "  Downloading multiqc-1.25.2-py3-none-any.whl.metadata (45 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from multiqc) (8.1.7)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from multiqc) (4.11.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from multiqc) (8.5.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from multiqc) (3.1.4)\n",
            "Collecting kaleido==0.2.1 (from multiqc)\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from multiqc) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from multiqc) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from multiqc) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from multiqc) (2.32.3)\n",
            "Requirement already satisfied: Pillow>=10 in /usr/local/lib/python3.10/dist-packages (from multiqc) (11.0.0)\n",
            "Requirement already satisfied: plotly>=5.18 in /usr/local/lib/python3.10/dist-packages (from multiqc) (5.24.1)\n",
            "Requirement already satisfied: pyyaml>=4 in /usr/local/lib/python3.10/dist-packages (from multiqc) (6.0.2)\n",
            "Requirement already satisfied: rich>=10 in /usr/local/lib/python3.10/dist-packages (from multiqc) (13.9.4)\n",
            "Collecting rich-click (from multiqc)\n",
            "  Downloading rich_click-1.8.4-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting coloredlogs (from multiqc)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting spectra>=0.0.10 (from multiqc)\n",
            "  Downloading spectra-0.0.11.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from multiqc) (2.9.2)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.10/dist-packages (from multiqc) (4.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from multiqc) (4.66.6)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from multiqc) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.0->multiqc) (3.0.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.18->multiqc) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->multiqc) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->multiqc) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->multiqc) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10->multiqc) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10->multiqc) (2.18.0)\n",
            "Collecting colormath>=3.0.0 (from spectra>=0.0.10->multiqc)\n",
            "  Downloading colormath-3.0.0.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->multiqc)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->multiqc) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->multiqc) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->multiqc) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->multiqc) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->multiqc) (2024.8.30)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from colormath>=3.0.0->spectra>=0.0.10->multiqc) (3.4.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10->multiqc) (0.1.2)\n",
            "Downloading multiqc-1.25.2-py3-none-any.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich_click-1.8.4-py3-none-any.whl (35 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: spectra, colormath\n",
            "  Building wheel for spectra (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectra: filename=spectra-0.0.11-py3-none-any.whl size=17465 sha256=7f8cee7d41125c4db15e7de897453d34ef9eccf69fa6564833d52f0bc4743aca\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/27/ec/cddaa9489a49ddcf702e1f4dc1791db28a3b0121e1ff254f97\n",
            "  Building wheel for colormath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colormath: filename=colormath-3.0.0-py3-none-any.whl size=39406 sha256=233c544617b3cd77c8e5e027ffa3995215b3c0b706b7885602e184c0b3b6faa7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b3/4d/c0738759c25a1df01958068f162cf2a9dc3ab1da8b972cfcfc\n",
            "Successfully built spectra colormath\n",
            "Installing collected packages: kaleido, humanfriendly, colormath, spectra, coloredlogs, rich-click, multiqc\n",
            "Successfully installed coloredlogs-15.0.1 colormath-3.0.0 humanfriendly-10.0 kaleido-0.2.1 multiqc-1.25.2 rich-click-1.8.4 spectra-0.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!multiqc . --filename concatenated_report.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_NivRtIc9fG",
        "outputId": "43d32436-a242-450e-c6ff-ca52d0068540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[91m///\u001b[0m \u001b]8;id=169859;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2mv1.25.2\u001b[0m\n",
            "\n",
            "\u001b[34m       file_search\u001b[0m | Search path: /content\n",
            "\u001b[2K         \u001b[34msearching\u001b[0m | \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m294/294\u001b[0m  \n",
            "\u001b[?25h\u001b[34m            fastqc\u001b[0m | Found 6 reports\n",
            "\u001b[34m     write_results\u001b[0m | Data        : concatenated_report_data\n",
            "\u001b[34m     write_results\u001b[0m | Report      : concatenated_report.html\n",
            "\u001b[34m           multiqc\u001b[0m | MultiQC complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r /content/concatenated_report_data.zip /content/concatenated_report_data\n",
        "files.download('concatenated_report_data.zip')\n",
        "files.download('concatenated_report.html')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "CciiCekEdKyI",
        "outputId": "adbd6e04-3dd0-4e51-a2c8-c4394056b353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/concatenated_report_data/ (stored 0%)\n",
            "  adding: content/concatenated_report_data/fastqc_sequence_duplication_levels_plot.txt (deflated 59%)\n",
            "  adding: content/concatenated_report_data/fastqc_top_overrepresented_sequences_table.txt (stored 0%)\n",
            "  adding: content/concatenated_report_data/multiqc_general_stats.txt (deflated 61%)\n",
            "  adding: content/concatenated_report_data/multiqc_data.json (deflated 92%)\n",
            "  adding: content/concatenated_report_data/fastqc_per_sequence_gc_content_plot_Counts.txt (deflated 67%)\n",
            "  adding: content/concatenated_report_data/fastqc_sequence_counts_plot.txt (deflated 41%)\n",
            "  adding: content/concatenated_report_data/multiqc.log (deflated 41%)\n",
            "  adding: content/concatenated_report_data/multiqc_software_versions.txt (deflated 11%)\n",
            "  adding: content/concatenated_report_data/fastqc_per_sequence_gc_content_plot_Percentages.txt (deflated 58%)\n",
            "  adding: content/concatenated_report_data/multiqc_fastqc.txt (deflated 71%)\n",
            "  adding: content/concatenated_report_data/fastqc-status-check-heatmap.txt (deflated 65%)\n",
            "  adding: content/concatenated_report_data/multiqc_sources.txt (deflated 71%)\n",
            "  adding: content/concatenated_report_data/fastqc_per_sequence_quality_scores_plot.txt (deflated 69%)\n",
            "  adding: content/concatenated_report_data/fastqc_per_base_sequence_quality_plot.txt (deflated 58%)\n",
            "  adding: content/concatenated_report_data/multiqc_citations.txt (deflated 29%)\n",
            "  adding: content/concatenated_report_data/fastqc_per_base_n_content_plot.txt (deflated 61%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_38da12b3-ea73-486e-97ad-95d4fb1def22\", \"concatenated_report_data.zip\", 68281)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_efd87085-08b5-4ad6-adfa-1371c691419f\", \"concatenated_report.html\", 4756492)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Отбор чтений\n",
        "\n",
        "Нужны те, которые картировались уникально (флаг NH:i:1)<br>"
      ],
      "metadata": {
        "id": "5DzrTLbnd0uM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414629_1.fastq -S SRR3414629_1.sam  2>  SRR3414629.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414629_1.sam > SRR3414629.uniq.sam\n",
        "!rm -v SRR3414629_1.sam\n",
        "!grep -v '^@' SRR3414629.uniq.sam | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9YlvIO_tnZf",
        "outputId": "82416b07-0931-4c89-8501-9d3c60329b39"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t24m22.169s\n",
            "user\t26m45.792s\n",
            "sys\t2m47.532s\n",
            "removed 'SRR3414629_1.sam'\n",
            "18573565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat SRR3414629.hisat\n",
        "!rm SRR3414629.hisat\n",
        "!rm SRR3414629_1.fastq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uZoCmT9zicA",
        "outputId": "e708aab5-0804-4c2c-860b-eaff5c327e0f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21106089 reads; of these:\n",
            "  21106089 (100.00%) were unpaired; of these:\n",
            "    241118 (1.14%) aligned 0 times\n",
            "    18573565 (88.00%) aligned exactly 1 time\n",
            "    2291406 (10.86%) aligned >1 times\n",
            "98.86% overall alignment rate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414630_1.fastq -S SRR3414630_1.sam  2>  SRR3414630.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414630_1.sam > SRR3414630.uniq.sam\n",
        "!rm -v SRR3414630_1.sam\n",
        "!grep -v '^@' SRR3414630.uniq.sam | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yck80Ti9zlV5",
        "outputId": "147bed37-15c1-41fd-cdb8-e295e1c8b4e7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t16m44.603s\n",
            "user\t18m37.382s\n",
            "sys\t1m51.343s\n",
            "removed 'SRR3414630_1.sam'\n",
            "13320505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat SRR3414630.hisat\n",
        "!rm SRR3414630.hisat\n",
        "!rm SRR3414630_1.fastq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80SE0pBx39sX",
        "outputId": "3d8b59f4-5cb6-47e0-e804-1064cc9a0665"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15244711 reads; of these:\n",
            "  15244711 (100.00%) were unpaired; of these:\n",
            "    168274 (1.10%) aligned 0 times\n",
            "    13320505 (87.38%) aligned exactly 1 time\n",
            "    1755932 (11.52%) aligned >1 times\n",
            "98.90% overall alignment rate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414631_1.fastq -S SRR3414631_1.sam  2>  SRR3414631.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414631_1.sam > SRR3414631.uniq.sam\n",
        "!rm -v SRR3414631_1.sam\n",
        "!grep -v '^@' SRR3414631.uniq.sam | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCalMWQI4Are",
        "outputId": "1ca033ef-236b-4095-9c61-396b867aac64"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t26m45.677s\n",
            "user\t30m17.509s\n",
            "sys\t2m59.263s\n",
            "removed 'SRR3414631_1.sam'\n",
            "21159606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat SRR3414631.hisat\n",
        "!rm SRR3414631.hisat\n",
        "!rm SRR3414631_1.fastq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR8UzPTR-uYX",
        "outputId": "6a5da265-660c-4556-ce5f-074bd62a0dbf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24244069 reads; of these:\n",
            "  24244069 (100.00%) were unpaired; of these:\n",
            "    279694 (1.15%) aligned 0 times\n",
            "    21159606 (87.28%) aligned exactly 1 time\n",
            "    2804769 (11.57%) aligned >1 times\n",
            "98.85% overall alignment rate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414635_1.fastq -S SRR3414635_1.sam  2>  SRR3414635.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414635_1.sam > SRR3414635.uniq.sam\n",
        "!rm -v SRR3414635_1.sam\n",
        "!grep -v '^@' SRR3414635.uniq.sam | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03f7vPH5-w3y",
        "outputId": "7382bc3f-64f0-4829-a750-33166a238693"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t22m57.047s\n",
            "user\t25m16.079s\n",
            "sys\t2m37.468s\n",
            "removed 'SRR3414635_1.sam'\n",
            "18637053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat SRR3414635.hisat\n",
        "!rm SRR3414635.hisat\n",
        "!rm SRR3414635_1.fastq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C02HWDQeFDtp",
        "outputId": "d99e5120-53b3-4981-b446-8a473facf06d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20956475 reads; of these:\n",
            "  20956475 (100.00%) were unpaired; of these:\n",
            "    242044 (1.15%) aligned 0 times\n",
            "    18637053 (88.93%) aligned exactly 1 time\n",
            "    2077378 (9.91%) aligned >1 times\n",
            "98.85% overall alignment rate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414636_1.fastq -S SRR3414636_1.sam  2>  SRR3414636.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414636_1.sam > SRR3414636.uniq.sam\n",
        "!rm -v SRR3414636_1.sam\n",
        "!grep -v '^@' SRR3414636.uniq.sam | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0hz8Z8lFGPT",
        "outputId": "d5d0efbb-382a-4121-bc5f-8eae1c816bfb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t22m15.718s\n",
            "user\t24m49.507s\n",
            "sys\t2m31.912s\n",
            "removed 'SRR3414636_1.sam'\n",
            "18032679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat SRR3414636.hisat\n",
        "!rm SRR3414636.hisat\n",
        "!rm SRR3414636_1.fastq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIVvOjP1Kl0b",
        "outputId": "0cfbdf06-ee6e-4c65-afa8-3405f392ba49"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20307147 reads; of these:\n",
            "  20307147 (100.00%) were unpaired; of these:\n",
            "    233551 (1.15%) aligned 0 times\n",
            "    18032679 (88.80%) aligned exactly 1 time\n",
            "    2040917 (10.05%) aligned >1 times\n",
            "98.85% overall alignment rate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414637_1.fastq -S SRR3414637_1.sam  2>  SRR3414637.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414637_1.sam > SRR3414637.uniq.sam\n",
        "!rm -v SRR3414637_1.sam\n",
        "!grep -v '^@' SRR3414637.uniq.sam | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXfd2rbyKuQ6",
        "outputId": "05cd0355-e3e1-4351-d902-06f72fcde21c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t22m4.016s\n",
            "user\t24m19.411s\n",
            "sys\t2m28.561s\n",
            "removed 'SRR3414637_1.sam'\n",
            "18043406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat SRR3414637.hisat\n",
        "!rm SRR3414637.hisat\n",
        "!rm SRR3414637_1.fastq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2doNkfnnSAai",
        "outputId": "f256b587-7d43-46f5-91a4-ffae53a01c71"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20385570 reads; of these:\n",
            "  20385570 (100.00%) were unpaired; of these:\n",
            "    236895 (1.16%) aligned 0 times\n",
            "    18043406 (88.51%) aligned exactly 1 time\n",
            "    2105269 (10.33%) aligned >1 times\n",
            "98.84% overall alignment rate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### С помощью программы `HTSeq` Подсчитываем количество чтений, попавших на каждый ген"
      ],
      "metadata": {
        "id": "mgg29qQvbivJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!time htseq-count --format=sam --stranded=no SRR3414629.uniq.sam  gencode.vM25.annotation.gtf > SRR3414629.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414630.uniq.sam  gencode.vM25.annotation.gtf > SRR3414630.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414631.uniq.sam  gencode.vM25.annotation.gtf > SRR3414631.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414635.uniq.sam  gencode.vM25.annotation.gtf > SRR3414635.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414636.uniq.sam  gencode.vM25.annotation.gtf > SRR3414636.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414637.uniq.sam  gencode.vM25.annotation.gtf > SRR3414637.counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utr0ezOMSH_z",
        "outputId": "49f90ef5-5869-4b6e-d3f9-0d9fb67636bd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18100000 alignment records processed.\n",
            "18200000 alignment records processed.\n",
            "18300000 alignment records processed.\n",
            "18400000 alignment records processed.\n",
            "18500000 alignment records processed.\n",
            "18573565 alignment records processed.\n",
            "\n",
            "real\t33m47.160s\n",
            "user\t31m5.502s\n",
            "sys\t0m43.584s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13320505 alignment records processed.\n",
            "\n",
            "real\t24m23.552s\n",
            "user\t22m37.598s\n",
            "sys\t0m33.025s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18100000 alignment records processed.\n",
            "18200000 alignment records processed.\n",
            "18300000 alignment records processed.\n",
            "18400000 alignment records processed.\n",
            "18500000 alignment records processed.\n",
            "18600000 alignment records processed.\n",
            "18700000 alignment records processed.\n",
            "18800000 alignment records processed.\n",
            "18900000 alignment records processed.\n",
            "19000000 alignment records processed.\n",
            "19100000 alignment records processed.\n",
            "19200000 alignment records processed.\n",
            "19300000 alignment records processed.\n",
            "19400000 alignment records processed.\n",
            "19500000 alignment records processed.\n",
            "19600000 alignment records processed.\n",
            "19700000 alignment records processed.\n",
            "19800000 alignment records processed.\n",
            "19900000 alignment records processed.\n",
            "20000000 alignment records processed.\n",
            "20100000 alignment records processed.\n",
            "20200000 alignment records processed.\n",
            "20300000 alignment records processed.\n",
            "20400000 alignment records processed.\n",
            "20500000 alignment records processed.\n",
            "20600000 alignment records processed.\n",
            "20700000 alignment records processed.\n",
            "20800000 alignment records processed.\n",
            "20900000 alignment records processed.\n",
            "21000000 alignment records processed.\n",
            "21100000 alignment records processed.\n",
            "21159606 alignment records processed.\n",
            "\n",
            "real\t38m2.520s\n",
            "user\t35m1.810s\n",
            "sys\t0m50.645s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18100000 alignment records processed.\n",
            "18200000 alignment records processed.\n",
            "18300000 alignment records processed.\n",
            "18400000 alignment records processed.\n",
            "18500000 alignment records processed.\n",
            "18600000 alignment records processed.\n",
            "18637053 alignment records processed.\n",
            "\n",
            "real\t33m42.893s\n",
            "user\t31m17.290s\n",
            "sys\t0m46.241s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18032679 alignment records processed.\n",
            "\n",
            "real\t32m36.582s\n",
            "user\t30m13.613s\n",
            "sys\t0m45.593s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18043406 alignment records processed.\n",
            "\n",
            "real\t32m34.681s\n",
            "user\t30m6.606s\n",
            "sys\t0m43.173s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Смотрим сколько чтений не удалось приписать ни одному гену:\n",
        "* `__no_feature ` – столько чтений соответствует участкам генома, где не аннотировано ни одного экзона\n",
        "* `__ambiguous ` – столько чтений могут принадлежать разным генам\n"
      ],
      "metadata": {
        "id": "KSTOKJrecoZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! grep '^__' SRR3414629.counts"
      ],
      "metadata": {
        "id": "TCe0vLS3PvUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbdfd602-ae6c-46e7-ada4-4e586a64e941"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1620359\n",
            "__ambiguous\t728893\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! grep '^__' SRR3414630.counts"
      ],
      "metadata": {
        "id": "YCJCGbNPPxHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18557fe1-4321-426d-8c5f-28d307969198"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1251763\n",
            "__ambiguous\t484967\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! grep '^__' SRR3414631.counts"
      ],
      "metadata": {
        "id": "cpbaVTXmPzDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d668ca23-57b7-45f7-9cbb-f786f03836b0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1718354\n",
            "__ambiguous\t827751\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! grep '^__' SRR3414635.counts"
      ],
      "metadata": {
        "id": "0gsbCG8UP0fR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c35ed77-94c4-47be-8870-0e62f6d2d180"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1406679\n",
            "__ambiguous\t767361\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! grep '^__' SRR3414636.counts"
      ],
      "metadata": {
        "id": "JB1YH_lsP17T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "527d9918-ef0b-4fca-8c42-61a4aa8b89ab"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1347210\n",
            "__ambiguous\t742802\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! grep '^__' SRR3414637.counts"
      ],
      "metadata": {
        "id": "FZn92CgqP3mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac90f492-7d31-4b84-96ab-4f005f407791"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1411488\n",
            "__ambiguous\t717538\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'общее число чтений SRR3414629: {18573565 - 1620359 - 728893}')\n",
        "print(f'общее число чтений SRR3414630: {13320505 - 1251763 - 484967}')\n",
        "print(f'общее число чтений SRR3414631: {21159606 - 1718354 - 827751}')\n",
        "print(f'общее число чтений SRR3414635: {18637053 - 1406679 - 767361}')\n",
        "print(f'общее число чтений SRR3414636: {18032679 - 1347210 - 742802}')\n",
        "print(f'общее число чтений SRR3414637: {18043406 - 1411488 - 717538}')"
      ],
      "metadata": {
        "id": "lgrCShZpP5hA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9605c91-a0a4-4e77-adcf-b9dd603dab71"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "общее число чтений SRR3414629: 16224313\n",
            "общее число чтений SRR3414630: 11583775\n",
            "общее число чтений SRR3414631: 18613501\n",
            "общее число чтений SRR3414635: 16463013\n",
            "общее число чтений SRR3414636: 15942667\n",
            "общее число чтений SRR3414637: 15914380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pA2KdzePngH",
        "outputId": "fb44c0a7-a984-47c2-825b-9d2dfcdfaa21"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas==2.2.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWs2Zy_cTGl9",
        "outputId": "9de9d673-ba91-4a7e-dc33-ec505d4f3eeb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas==2.2.2\n",
            "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.16.0)\n",
            "Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.1\n",
            "    Uninstalling pandas-2.1.1:\n",
            "      Successfully uninstalled pandas-2.1.1\n",
            "Successfully installed pandas-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "К сожалению, в коллабе возникла локальная проблема с работой numpy\n",
        "\n",
        "Ни один вариант из найденнных в интернете не помог, поэтому я приняла решение скачать получившиеся файлы и продолжить работу в Jupyter Notebook"
      ],
      "metadata": {
        "id": "-cbZHjambm8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "c1 = pd.read_csv('SRR3414635.counts', names=['geneID', 'c1'])\n",
        "c2 = pd.read_csv('SRR3414636.counts',  names=['geneID', 'c2'])\n",
        "c3 = pd.read_csv('SRR3414637.counts',  names=['geneID', 'c3'])\n",
        "r1 = pd.read_csv('SRR3414629.counts', sep=\"\\t\",  names=['geneID', 'r1'])\n",
        "r2 = pd.read_csv('SRR3414630.counts', sep=\"\\t\",  names=['geneID', 'r2'])\n",
        "r3 = pd.read_csv('SRR3414631.counts', sep=\"\\t\",  names=['geneID', 'r3'])\n",
        "\n",
        "c1 = c1.merge(c2, how='left', on='geneID')\n",
        "c1 = c1.merge(c3, how='left', on='geneID')\n",
        "c1 = c1.merge(r1, how='left', on='geneID')\n",
        "c1 = c1.merge(r2, how='left', on='geneID')\n",
        "c1 = c1.merge(r3, how='left', on='geneID')\n",
        "\n",
        "ALL_cnts = c1[:-5]\n",
        "ALL_cnts"
      ],
      "metadata": {
        "id": "dKT0oq3dP8S_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "8eb7c187-bbc0-4ec7-c4ae-626296d11728"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Cannot convert numpy.ndarray to numpy.ndarray",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-89d2ce4b69a5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SRR3414635.counts'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geneID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SRR3414636.counts'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geneID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SRR3414637.counts'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geneID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1966\u001b[0m                 \u001b[0mnew_col_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1968\u001b[0;31m             df = DataFrame(\n\u001b[0m\u001b[1;32m   1969\u001b[0m                 \u001b[0mnew_col_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m                 \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7645\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7647\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7648\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7649\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"index must be specified when data is not list-like\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_platform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_convert_platform\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_dtype_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot convert numpy.ndarray to numpy.ndarray"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/SRR3414629.counts')"
      ],
      "metadata": {
        "id": "PujTqPQIXwg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/SRR3414630.counts')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "40Cko0LgVNiX",
        "outputId": "cdfadc99-0c8a-4b8f-c7ef-13a11dd8f89b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0b576986-5c94-4cdc-989a-c0181b4be385\", \"SRR3414630.counts\", 1313906)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/SRR3414631.counts')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OAviDVhyVVBC",
        "outputId": "30c3fdb8-2d39-414e-b244-9aa3546766cd"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_35a65ee3-e8f0-49b9-93dc-765cfaca5e7c\", \"SRR3414631.counts\", 1317782)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/SRR3414635.counts')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "R0herUiWVheC",
        "outputId": "da0312eb-54f9-4261-c6fe-77c6fddf3d12"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_627fcfcd-546e-42c2-be32-37fcf460f11d\", \"SRR3414635.counts\", 1314958)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/SRR3414636.counts')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "q9t1cwuLVl34",
        "outputId": "0abbeb91-b1bf-4c8c-dabe-85c20aed9526"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ca7c51bb-9628-4a90-a1c2-4aea031be5ba\", \"SRR3414636.counts\", 1314633)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/SRR3414637.counts')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2OWKSuUOVofn",
        "outputId": "3837dcaa-9d29-434f-c242-31b19a175753"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_27513bf5-add9-48de-9642-9dcb6dcea6ae\", \"SRR3414637.counts\", 1314619)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}